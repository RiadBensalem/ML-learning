{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest \n",
    "Dans ce TP, on s'interesse au développement et à l'utilisation d'un modèle de forêt d'arbres décisionnels sous python. Nous commencerons par l'implémentation et la compréhension d'un arbre de décision qui constitue le bloc de construction d'un modèle Random Forest. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Arbre de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split  # Pour diviser nos données en trainset et testset. \n",
    "from sklearn.tree import DecisionTreeClassifier # Créer le modèle DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score # Calculer le score du modèle \n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset : \n",
    "Dans cet example nous allons utiliser \"Balance Scale\" Dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Lire la base de données trouvée dans dataset/balance-scale.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Explorer la base de données (taille, nombre de features, y a t-il de valeur à null ? )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Remplir avec les bons indices \n",
    "X = balance_data.values[]\n",
    "Y = balance_data.values[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier()\n",
    "DecisionTreeClassifier(): est la fonction qui définit le modèle d'arbre de décision. Quelques paramètres important sont : \n",
    "* criterion : la fonction de gain d'information (Entropy utilisée dans le cours, il existe aussi Gini très utilisée) \n",
    "* splitter : La stratégie de choix du noeud de séparation. (Best, random) \n",
    "* max_features : Le nombre de variables à considérer lors du choix du meilleur noeud de séparation. \n",
    "* max_depth : La profondeur maximale de l'arbre. \n",
    "* min_impurity_split : Un noeud sera séparé si le calcul de son impureté dépasse cette valeur sinon se sera une feuille. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Donner les bonnes valeurs aux paramètres.\n",
    "model = DecisionTreeClassifier(criterion = , max_depth= , splitter= , min_impurity_split= )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(model, out_file='tree_limited.dot', \n",
    "                rounded = True, proportion = False, precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux : \n",
    "#!dot -Tpng tree_limited.dot -o tree_limited.png -Gdpi=600\n",
    "\n",
    "# Windows : \n",
    "!C:\\\"Program Files (x86)\"\\Graphviz2.38\\bin\\dot.exe -Tpng tree_limited.dot -o tree_limited.png -Gdpi=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = 'tree_limited.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[4, 4, 3, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la classe prédite pour chacune des valeurs de X_train et X_test \n",
    "y_train_pred = \n",
    "h = \n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy is \", accuracy_score(y_train,y_train_pred)*100)\n",
    "print(\"Test Accuracy is \", accuracy_score(y_test,h)*100)\n",
    "\n",
    "# TODO : Comparer les deux valeurs, que constatez-vous ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exemple d'un arbre de décision réel avec 50 features \n",
    "![](images/1_hW67kyPZZJ6I_7Z8huwDkg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif des forêts d'arbres décisionnels est d'éviter le surapprentissage sur les données d'entraînement et les généralisations la plus adéquate pour mieux prédire aux nouvelles données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les étapes de base impliquées dans l'exécution de l'algorithme de forêt aléatoire:\n",
    "\n",
    "* Choisissez N enregistrements aléatoires dans le jeu de données.\n",
    "* Construisez un arbre de décision basé sur ces N enregistrements.\n",
    "* Choisissez le nombre d'arbres souhaité dans votre algorithme et répétez les étapes 1 et 2.\n",
    "* En cas de problème de régression, pour un nouvel enregistrement, chaque arbre de la forêt prédit une valeur pour Y (sortie). La valeur finale peut être calculée en prenant la moyenne de toutes les valeurs prédites par tous les arbres en forêt. Ou, en cas de problème de classification, chaque arbre de la forêt prédit la catégorie à laquelle appartient le nouvel enregistrement. Enfin, le nouvel enregistrement est attribué à la catégorie qui remporte le vote à la majorité.\n",
    "\n",
    "### Random forest pour la régression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./dataset/petrol_consumption.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Diviser le dataset (Trainset : 80%)\n",
    "X_train, X_test, y_train, y_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "regressor.fit(X_train, y_train)  \n",
    "y_pred = regressor.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_train_pred = regressor.predict(X_train) \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_train_pred)) \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = [20*i for i in range(1,11)]\n",
    "errors = []\n",
    "for n in n_estimator:\n",
    "    regressor = RandomForestRegressor(n_estimators=n, random_state=0)  \n",
    "    regressor.fit(X_train, y_train)  \n",
    "    y_pred = regressor.predict(X_test) \n",
    "    errors.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(n_estimator,errors, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest pour la classification \n",
    "Le but ici est de prédire si un billet de banque est authentique ou pas sur la base de 4 attributs; ex : la variance de l’image transformée, l’asymétrie, l’entropie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/bill_authentication.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "regressor.fit(X_train, y_train)  \n",
    "y_pred = regressor.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred.round()))  \n",
    "print(classification_report(y_test,y_pred.round()))  \n",
    "print(accuracy_score(y_test, y_pred.round())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Plotter le graphe des accuracy par rapport au changement du n_estimators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
